"""
æ€§èƒ½ä¼˜åŒ–ç³»ç»Ÿæµ‹è¯•è„šæœ¬

æµ‹è¯•ä»»åŠ¡é˜Ÿåˆ—ã€èµ„æºç›‘æ§å’Œæµå¼ä¼˜åŒ–åŠŸèƒ½
"""

import asyncio
import os
import sys
import time
import logging

# æ·»åŠ å½“å‰ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))


async def test_task_queue():
    """æµ‹è¯•ä»»åŠ¡é˜Ÿåˆ—"""
    logging.info("ğŸ§ª æµ‹è¯•ä»»åŠ¡é˜Ÿåˆ—...")

    try:
        from utils.task_queue import TaskQueue, TaskPriority
        
        # åˆ›å»ºä»»åŠ¡é˜Ÿåˆ—
        queue = TaskQueue(max_workers=2, max_queue_size=10)
        await queue.start()
        
        # æµ‹è¯•å‡½æ•°
        async def test_task(x, y):
            await asyncio.sleep(0.1)  # æ¨¡æ‹Ÿå·¥ä½œ
            return x + y
        
        # æäº¤ä»»åŠ¡
        task_id1 = await queue.submit_task(test_task, 1, 2, priority=TaskPriority.HIGH)
        task_id2 = await queue.submit_task(test_task, 3, 4, priority=TaskPriority.NORMAL)
        
        # ç­‰å¾…ä»»åŠ¡å®Œæˆ
        await asyncio.sleep(0.5)
        
        # æ£€æŸ¥ä»»åŠ¡çŠ¶æ€
        status1 = queue.get_task_status(task_id1)
        status2 = queue.get_task_status(task_id2)
        
        assert status1 is not None, "ä»»åŠ¡1çŠ¶æ€ä¸åº”ä¸ºç©º"
        assert status2 is not None, "ä»»åŠ¡2çŠ¶æ€ä¸åº”ä¸ºç©º"
        
        # è·å–ç»Ÿè®¡ä¿¡æ¯
        stats = queue.get_queue_stats()
        assert stats["total_tasks"] >= 2, "æ€»ä»»åŠ¡æ•°åº”è¯¥è‡³å°‘ä¸º2"
        
        await queue.stop()
        
        logging.info("âœ… ä»»åŠ¡é˜Ÿåˆ—æµ‹è¯•é€šè¿‡")
        return True

    except Exception as e:
        logging.error(f"âŒ ä»»åŠ¡é˜Ÿåˆ—æµ‹è¯•å¤±è´¥: {e}")
        return False


async def test_resource_monitor():
    """æµ‹è¯•èµ„æºç›‘æ§"""
    logging.info("ğŸ§ª æµ‹è¯•èµ„æºç›‘æ§...")
    
    try:
        from utils.resource_monitor import ResourceMonitor
        
        # åˆ›å»ºèµ„æºç›‘æ§å™¨
        monitor = ResourceMonitor(history_size=10, sample_interval=0.1)
        
        # å¯åŠ¨ç›‘æ§
        await monitor.start_monitoring()
        
        # ç­‰å¾…æ”¶é›†ä¸€äº›æ•°æ®
        await asyncio.sleep(0.5)
        
        # è·å–å½“å‰çŠ¶æ€
        current_status = monitor.get_current_status()
        assert current_status is not None, "å½“å‰çŠ¶æ€ä¸åº”ä¸ºç©º"
        assert current_status.cpu_percent >= 0, "CPUä½¿ç”¨ç‡åº”è¯¥å¤§äºç­‰äº0"
        assert current_status.memory_percent >= 0, "å†…å­˜ä½¿ç”¨ç‡åº”è¯¥å¤§äºç­‰äº0"
        
        # è·å–ç»Ÿè®¡ä¿¡æ¯
        stats = monitor.get_statistics(minutes=1)
        assert "cpu" in stats, "ç»Ÿè®¡ä¿¡æ¯åº”åŒ…å«CPUæ•°æ®"
        assert "memory" in stats, "ç»Ÿè®¡ä¿¡æ¯åº”åŒ…å«å†…å­˜æ•°æ®"
        
        # æµ‹è¯•é˜ˆå€¼è®¾ç½®
        monitor.set_thresholds(cpu_warning=50.0, memory_warning=50.0)
        
        await monitor.stop_monitoring()
        
        logging.info("âœ… èµ„æºç›‘æ§æµ‹è¯•é€šè¿‡")
        return True

    except Exception as e:
        logging.error(f"âŒ èµ„æºç›‘æ§æµ‹è¯•å¤±è´¥: {e}")
        return False


async def test_streaming_optimizer():
    """æµ‹è¯•æµå¼ä¼˜åŒ–å™¨"""
    logging.info("ğŸ§ª æµ‹è¯•æµå¼ä¼˜åŒ–å™¨...")
    
    try:
        from utils.streaming_optimizer import StreamingOptimizer
        
        optimizer = StreamingOptimizer(buffer_size=100, flush_interval=0.1)
        
        # æµ‹è¯•æ•°æ®ç”Ÿæˆå™¨
        async def test_data_generator():
            for i in range(5):
                yield f"chunk_{i} "
                await asyncio.sleep(0.01)
        
        # æµ‹è¯•ç¼“å†²æµ
        chunks = []
        async for chunk in optimizer.stream_with_buffer(test_data_generator()):
            chunks.append(chunk)
        
        assert len(chunks) > 0, "åº”è¯¥äº§ç”Ÿè‡³å°‘ä¸€ä¸ªæ•°æ®å—"
        combined = ''.join(chunks)
        assert "chunk_0" in combined, "åº”è¯¥åŒ…å«ç¬¬ä¸€ä¸ªæ•°æ®å—"
        assert "chunk_4" in combined, "åº”è¯¥åŒ…å«æœ€åä¸€ä¸ªæ•°æ®å—"
        
        # æµ‹è¯•JSONæµ
        async def test_json_generator():
            for i in range(3):
                yield {"index": i, "data": f"test_{i}"}
                await asyncio.sleep(0.01)
        
        json_chunks = []
        async for chunk in optimizer.stream_json_chunks(test_json_generator()):
            json_chunks.append(chunk)
        
        assert len(json_chunks) >= 3, "åº”è¯¥äº§ç”Ÿè‡³å°‘3ä¸ªJSONæ•°æ®å—"
        
        logging.info("âœ… æµå¼ä¼˜åŒ–å™¨æµ‹è¯•é€šè¿‡")
        return True

    except Exception as e:
        logging.error(f"âŒ æµå¼ä¼˜åŒ–å™¨æµ‹è¯•å¤±è´¥: {e}")
        return False


async def test_performance_stt_service():
    """æµ‹è¯•é«˜æ€§èƒ½è½¬å½•æœåŠ¡"""
    logging.info("ğŸ§ª æµ‹è¯•é«˜æ€§èƒ½è½¬å½•æœåŠ¡...")
    
    try:
        from services.performance_stt_service import PerformanceSTTService
        
        service = PerformanceSTTService()
        
        # æµ‹è¯•åˆå§‹åŒ–
        await service.initialize()
        
        # è·å–æœåŠ¡ç»Ÿè®¡
        stats = service.get_service_stats()
        assert "service_stats" in stats, "ç»Ÿè®¡ä¿¡æ¯åº”åŒ…å«æœåŠ¡ç»Ÿè®¡"
        assert "queue_stats" in stats, "ç»Ÿè®¡ä¿¡æ¯åº”åŒ…å«é˜Ÿåˆ—ç»Ÿè®¡"
        
        # æµ‹è¯•æ€§èƒ½ä¼˜åŒ–
        await service.optimize_performance()
        
        # å…³é—­æœåŠ¡
        await service.shutdown()
        
        logging.info("âœ… é«˜æ€§èƒ½è½¬å½•æœåŠ¡æµ‹è¯•é€šè¿‡")
        return True

    except Exception as e:
        logging.error(f"âŒ é«˜æ€§èƒ½è½¬å½•æœåŠ¡æµ‹è¯•å¤±è´¥: {e}")
        return False


async def test_simple_cache_performance():
    """æµ‹è¯•ç¼“å­˜æ€§èƒ½"""
    logging.info("ğŸ§ª æµ‹è¯•ç¼“å­˜æ€§èƒ½...")
    
    try:
        from utils.simple_cache import SimpleCache
        
        cache = SimpleCache(max_size=1000)
        
        # æ€§èƒ½æµ‹è¯•
        start_time = time.time()
        
        # å†™å…¥æµ‹è¯•
        for i in range(100):
            cache.set(f"key_{i}", f"value_{i}")
        
        write_time = time.time() - start_time
        
        # è¯»å–æµ‹è¯•
        start_time = time.time()
        hits = 0
        for i in range(100):
            if cache.get(f"key_{i}") is not None:
                hits += 1
        
        read_time = time.time() - start_time
        
        assert hits == 100, f"åº”è¯¥å‘½ä¸­100æ¬¡ï¼Œå®é™…å‘½ä¸­{hits}æ¬¡"
        assert write_time < 1.0, f"å†™å…¥æ—¶é—´è¿‡é•¿: {write_time:.3f}s"
        assert read_time < 1.0, f"è¯»å–æ—¶é—´è¿‡é•¿: {read_time:.3f}s"
        
        # è·å–ç»Ÿè®¡
        stats = cache.get_stats()
        assert stats["size"] == 100, f"ç¼“å­˜å¤§å°åº”ä¸º100ï¼Œå®é™…ä¸º{stats['size']}"
        
        logging.info(f"âœ… ç¼“å­˜æ€§èƒ½æµ‹è¯•é€šè¿‡ (å†™å…¥: {write_time:.3f}s, è¯»å–: {read_time:.3f}s)")
        return True

    except Exception as e:
        logging.error(f"âŒ ç¼“å­˜æ€§èƒ½æµ‹è¯•å¤±è´¥: {e}")
        return False


async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    logging.info("ğŸš€ å¼€å§‹æ€§èƒ½ä¼˜åŒ–ç³»ç»Ÿæµ‹è¯•...")
    
    tests = [
        ("ä»»åŠ¡é˜Ÿåˆ—", test_task_queue),
        ("èµ„æºç›‘æ§", test_resource_monitor),
        ("æµå¼ä¼˜åŒ–å™¨", test_streaming_optimizer),
        ("é«˜æ€§èƒ½è½¬å½•æœåŠ¡", test_performance_stt_service),
        ("ç¼“å­˜æ€§èƒ½", test_simple_cache_performance),
    ]
    
    passed = 0
    total = len(tests)
    
    for test_name, test_func in tests:
        logging.info(f"--- {test_name} ---")
        try:
            if await test_func():
                passed += 1
        except Exception as e:
            logging.error(f"âŒ {test_name} æµ‹è¯•å¼‚å¸¸: {e}")

    logging.info("=" * 50)
    logging.info(f"æµ‹è¯•ç»“æœ: {passed}/{total} é€šè¿‡")

    if passed == total:
        logging.info("ğŸ‰ æ‰€æœ‰æ€§èƒ½ä¼˜åŒ–æµ‹è¯•é€šè¿‡ï¼")
        return True
    else:
        logging.warning("âš ï¸ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç›¸å…³æ¨¡å—")
        return False


if __name__ == "__main__":
    success = asyncio.run(main())
    sys.exit(0 if success else 1)
