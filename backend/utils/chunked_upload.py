"""
åˆ†ç‰‡ä¸Šä¼ ç³»ç»Ÿ

æ”¯æŒå¤§æ–‡ä»¶åˆ†ç‰‡ä¸Šä¼ ã€æ–­ç‚¹ç»­ä¼ ã€è¿›åº¦åé¦ˆç­‰åŠŸèƒ½
"""

import asyncio
import hashlib
import json
import logging
import os
import tempfile
import time
from dataclasses import dataclass
from typing import Dict, List, Optional, AsyncGenerator, BinaryIO
from pathlib import Path

from utils.progress_manager import progress_manager, TaskType, TaskStatus


@dataclass
class ChunkInfo:
    """åˆ†ç‰‡ä¿¡æ¯"""
    chunk_id: int
    chunk_hash: str
    chunk_size: int
    start_byte: int
    end_byte: int
    uploaded: bool = False
    upload_time: Optional[float] = None


@dataclass
class UploadSession:
    """ä¸Šä¼ ä¼šè¯"""
    session_id: str
    task_id: str
    file_name: str
    file_size: int
    total_chunks: int
    chunk_size: int
    file_hash: str
    chunks: List[ChunkInfo]
    temp_dir: str
    created_at: float
    last_activity: float
    completed: bool = False


class ChunkedUploadManager:
    """åˆ†ç‰‡ä¸Šä¼ ç®¡ç†å™¨"""
    
    def __init__(self, chunk_size: int = 2 * 1024 * 1024, max_sessions: int = 100):
        """
        åˆå§‹åŒ–åˆ†ç‰‡ä¸Šä¼ ç®¡ç†å™¨
        
        Args:
            chunk_size: åˆ†ç‰‡å¤§å°ï¼ˆé»˜è®¤2MBï¼‰
            max_sessions: æœ€å¤§ä¼šè¯æ•°
        """
        self.chunk_size = chunk_size
        self.max_sessions = max_sessions
        self.sessions: Dict[str, UploadSession] = {}
        self.temp_base_dir = tempfile.gettempdir()
        self.session_timeout = 3600  # 1å°æ—¶è¶…æ—¶
        
    async def create_upload_session(
        self,
        file_name: str,
        file_size: int,
        file_hash: str,
        chunk_size: Optional[int] = None
    ) -> str:
        """
        åˆ›å»ºä¸Šä¼ ä¼šè¯
        
        Args:
            file_name: æ–‡ä»¶å
            file_size: æ–‡ä»¶å¤§å°
            file_hash: æ–‡ä»¶å“ˆå¸Œå€¼
            chunk_size: åˆ†ç‰‡å¤§å°ï¼ˆå¯é€‰ï¼‰
        
        Returns:
            ä¼šè¯ID
        """
        # æ¸…ç†è¿‡æœŸä¼šè¯
        await self._cleanup_expired_sessions()
        
        # æ£€æŸ¥ä¼šè¯æ•°é‡é™åˆ¶
        if len(self.sessions) >= self.max_sessions:
            raise Exception("ä¸Šä¼ ä¼šè¯æ•°é‡å·²è¾¾ä¸Šé™")
        
        # ä½¿ç”¨æŒ‡å®šçš„åˆ†ç‰‡å¤§å°æˆ–é»˜è®¤å€¼
        actual_chunk_size = chunk_size or self.chunk_size
        
        # è®¡ç®—åˆ†ç‰‡ä¿¡æ¯
        total_chunks = (file_size + actual_chunk_size - 1) // actual_chunk_size
        chunks = []
        
        for i in range(total_chunks):
            start_byte = i * actual_chunk_size
            end_byte = min(start_byte + actual_chunk_size - 1, file_size - 1)
            chunk_size_actual = end_byte - start_byte + 1
            
            chunk_info = ChunkInfo(
                chunk_id=i,
                chunk_hash="",  # å°†åœ¨ä¸Šä¼ æ—¶è®¡ç®—
                chunk_size=chunk_size_actual,
                start_byte=start_byte,
                end_byte=end_byte
            )
            chunks.append(chunk_info)
        
        # åˆ›å»ºä¸´æ—¶ç›®å½•
        session_id = hashlib.md5(f"{file_name}_{file_size}_{time.time()}".encode()).hexdigest()
        temp_dir = os.path.join(self.temp_base_dir, f"upload_{session_id}")
        os.makedirs(temp_dir, exist_ok=True)
        
        # åˆ›å»ºè¿›åº¦ä»»åŠ¡
        task_id = progress_manager.create_task(
            task_type=TaskType.UPLOAD,
            file_name=file_name,
            file_size=file_size,
            total_steps=total_chunks,
            metadata={
                'session_id': session_id,
                'chunk_size': actual_chunk_size,
                'file_hash': file_hash
            }
        )
        
        # åˆ›å»ºä¸Šä¼ ä¼šè¯
        session = UploadSession(
            session_id=session_id,
            task_id=task_id,
            file_name=file_name,
            file_size=file_size,
            total_chunks=total_chunks,
            chunk_size=actual_chunk_size,
            file_hash=file_hash,
            chunks=chunks,
            temp_dir=temp_dir,
            created_at=time.time(),
            last_activity=time.time()
        )
        
        self.sessions[session_id] = session
        
        # æ›´æ–°è¿›åº¦
        progress_manager.update_progress(
            task_id=task_id,
            status=TaskStatus.INITIALIZING,
            current_step="å‡†å¤‡åˆ†ç‰‡ä¸Šä¼ ",
            progress=0.0
        )
        
        logging.info(f"ğŸ“¦ åˆ›å»ºåˆ†ç‰‡ä¸Šä¼ ä¼šè¯: {session_id} - {file_name} ({file_size} bytes, {total_chunks} chunks)")
        return session_id
    
    async def upload_chunk(
        self,
        session_id: str,
        chunk_id: int,
        chunk_data: bytes
    ) -> bool:
        """
        ä¸Šä¼ åˆ†ç‰‡
        
        Args:
            session_id: ä¼šè¯ID
            chunk_id: åˆ†ç‰‡ID
            chunk_data: åˆ†ç‰‡æ•°æ®
        
        Returns:
            æ˜¯å¦ä¸Šä¼ æˆåŠŸ
        """
        if session_id not in self.sessions:
            raise Exception(f"ä¸Šä¼ ä¼šè¯ä¸å­˜åœ¨: {session_id}")
        
        session = self.sessions[session_id]
        session.last_activity = time.time()
        
        if chunk_id >= len(session.chunks):
            raise Exception(f"æ— æ•ˆçš„åˆ†ç‰‡ID: {chunk_id}")
        
        chunk_info = session.chunks[chunk_id]
        
        # éªŒè¯åˆ†ç‰‡å¤§å°
        if len(chunk_data) != chunk_info.chunk_size:
            raise Exception(f"åˆ†ç‰‡å¤§å°ä¸åŒ¹é…: æœŸæœ› {chunk_info.chunk_size}, å®é™… {len(chunk_data)}")
        
        # è®¡ç®—åˆ†ç‰‡å“ˆå¸Œ
        chunk_hash = hashlib.md5(chunk_data).hexdigest()
        chunk_info.chunk_hash = chunk_hash
        
        # ä¿å­˜åˆ†ç‰‡åˆ°ä¸´æ—¶æ–‡ä»¶
        chunk_file_path = os.path.join(session.temp_dir, f"chunk_{chunk_id:06d}")
        with open(chunk_file_path, 'wb') as f:
            f.write(chunk_data)
        
        # æ ‡è®°åˆ†ç‰‡å·²ä¸Šä¼ 
        chunk_info.uploaded = True
        chunk_info.upload_time = time.time()
        
        # è®¡ç®—ä¸Šä¼ è¿›åº¦
        uploaded_chunks = sum(1 for chunk in session.chunks if chunk.uploaded)
        progress = (uploaded_chunks / session.total_chunks) * 100
        
        # è®¡ç®—ä¸Šä¼ é€Ÿåº¦
        uploaded_size = sum(chunk.chunk_size for chunk in session.chunks if chunk.uploaded)
        elapsed_time = time.time() - session.created_at
        speed = f"{uploaded_size / elapsed_time / 1024 / 1024:.2f} MB/s" if elapsed_time > 0 else "0 MB/s"
        
        # ä¼°ç®—å‰©ä½™æ—¶é—´
        if uploaded_chunks > 0 and uploaded_chunks < session.total_chunks:
            avg_time_per_chunk = elapsed_time / uploaded_chunks
            remaining_chunks = session.total_chunks - uploaded_chunks
            eta_seconds = avg_time_per_chunk * remaining_chunks
            eta = f"{eta_seconds:.0f}s"
        else:
            eta = "Unknown"
        
        # æ›´æ–°è¿›åº¦
        progress_manager.update_progress(
            task_id=session.task_id,
            status=TaskStatus.PROCESSING,
            progress=progress,
            current_step=f"ä¸Šä¼ åˆ†ç‰‡ {uploaded_chunks}/{session.total_chunks}",
            current_step_index=uploaded_chunks,
            processed_size=uploaded_size,
            speed=speed,
            eta=eta
        )
        
        logging.info(f"ğŸ“¤ åˆ†ç‰‡ä¸Šä¼ å®Œæˆ: {session_id} chunk {chunk_id} ({progress:.1f}%)")
        
        # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰åˆ†ç‰‡éƒ½å·²ä¸Šä¼ 
        if uploaded_chunks == session.total_chunks:
            await self._merge_chunks(session_id)
        
        return True
    
    async def _merge_chunks(self, session_id: str) -> str:
        """
        åˆå¹¶åˆ†ç‰‡
        
        Args:
            session_id: ä¼šè¯ID
        
        Returns:
            åˆå¹¶åçš„æ–‡ä»¶è·¯å¾„
        """
        session = self.sessions[session_id]
        
        # æ›´æ–°è¿›åº¦
        progress_manager.update_progress(
            task_id=session.task_id,
            status=TaskStatus.PROCESSING,
            current_step="åˆå¹¶åˆ†ç‰‡æ–‡ä»¶",
            progress=95.0
        )
        
        # åˆ›å»ºæœ€ç»ˆæ–‡ä»¶è·¯å¾„
        final_file_path = os.path.join("uploads", session.file_name)
        os.makedirs(os.path.dirname(final_file_path), exist_ok=True)
        
        # åˆå¹¶åˆ†ç‰‡
        with open(final_file_path, 'wb') as final_file:
            for chunk_info in session.chunks:
                chunk_file_path = os.path.join(session.temp_dir, f"chunk_{chunk_info.chunk_id:06d}")
                
                if not os.path.exists(chunk_file_path):
                    raise Exception(f"åˆ†ç‰‡æ–‡ä»¶ä¸å­˜åœ¨: {chunk_info.chunk_id}")
                
                with open(chunk_file_path, 'rb') as chunk_file:
                    final_file.write(chunk_file.read())
        
        # éªŒè¯æ–‡ä»¶å®Œæ•´æ€§
        with open(final_file_path, 'rb') as f:
            file_hash = hashlib.md5(f.read()).hexdigest()
        
        if file_hash != session.file_hash:
            raise Exception(f"æ–‡ä»¶å“ˆå¸ŒéªŒè¯å¤±è´¥: æœŸæœ› {session.file_hash}, å®é™… {file_hash}")
        
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        await self._cleanup_session_files(session_id)
        
        # æ ‡è®°ä¼šè¯å®Œæˆ
        session.completed = True
        
        # å®Œæˆè¿›åº¦ä»»åŠ¡
        progress_manager.complete_task(
            task_id=session.task_id,
            success=True,
            result_metadata={
                'file_path': final_file_path,
                'file_hash': file_hash,
                'upload_duration': time.time() - session.created_at
            }
        )
        
        logging.info(f"âœ… åˆ†ç‰‡åˆå¹¶å®Œæˆ: {session_id} -> {final_file_path}")
        return final_file_path
    
    async def get_upload_status(self, session_id: str) -> Dict:
        """
        è·å–ä¸Šä¼ çŠ¶æ€
        
        Args:
            session_id: ä¼šè¯ID
        
        Returns:
            ä¸Šä¼ çŠ¶æ€ä¿¡æ¯
        """
        if session_id not in self.sessions:
            raise Exception(f"ä¸Šä¼ ä¼šè¯ä¸å­˜åœ¨: {session_id}")
        
        session = self.sessions[session_id]
        uploaded_chunks = [chunk for chunk in session.chunks if chunk.uploaded]
        missing_chunks = [chunk.chunk_id for chunk in session.chunks if not chunk.uploaded]
        
        # è·å–è¿›åº¦ä»»åŠ¡ä¿¡æ¯
        task_info = progress_manager.get_task_dict(session.task_id)
        
        return {
            'session_id': session_id,
            'task_id': session.task_id,
            'file_name': session.file_name,
            'file_size': session.file_size,
            'total_chunks': session.total_chunks,
            'uploaded_chunks': len(uploaded_chunks),
            'missing_chunks': missing_chunks,
            'progress': len(uploaded_chunks) / session.total_chunks * 100,
            'completed': session.completed,
            'task_info': task_info
        }
    
    async def cancel_upload(self, session_id: str) -> bool:
        """
        å–æ¶ˆä¸Šä¼ 
        
        Args:
            session_id: ä¼šè¯ID
        
        Returns:
            æ˜¯å¦å–æ¶ˆæˆåŠŸ
        """
        if session_id not in self.sessions:
            return False
        
        session = self.sessions[session_id]
        
        # å–æ¶ˆè¿›åº¦ä»»åŠ¡
        progress_manager.cancel_task(session.task_id)
        
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        await self._cleanup_session_files(session_id)
        
        # åˆ é™¤ä¼šè¯
        del self.sessions[session_id]
        
        logging.info(f"â¹ï¸ å–æ¶ˆåˆ†ç‰‡ä¸Šä¼ : {session_id}")
        return True
    
    async def _cleanup_session_files(self, session_id: str):
        """æ¸…ç†ä¼šè¯ä¸´æ—¶æ–‡ä»¶"""
        if session_id not in self.sessions:
            return
        
        session = self.sessions[session_id]
        temp_dir = session.temp_dir
        
        if os.path.exists(temp_dir):
            import shutil
            shutil.rmtree(temp_dir)
            logging.info(f"ğŸ§¹ æ¸…ç†ä¸´æ—¶æ–‡ä»¶: {temp_dir}")
    
    async def _cleanup_expired_sessions(self):
        """æ¸…ç†è¿‡æœŸä¼šè¯"""
        current_time = time.time()
        expired_sessions = []
        
        for session_id, session in self.sessions.items():
            if current_time - session.last_activity > self.session_timeout:
                expired_sessions.append(session_id)
        
        for session_id in expired_sessions:
            await self.cancel_upload(session_id)
        
        if expired_sessions:
            logging.info(f"ğŸ§¹ æ¸…ç†äº† {len(expired_sessions)} ä¸ªè¿‡æœŸä¸Šä¼ ä¼šè¯")
    
    def get_stats(self) -> Dict:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        active_sessions = len(self.sessions)
        completed_sessions = sum(1 for session in self.sessions.values() if session.completed)
        
        return {
            'active_sessions': active_sessions,
            'completed_sessions': completed_sessions,
            'max_sessions': self.max_sessions,
            'default_chunk_size': self.chunk_size,
            'session_timeout': self.session_timeout
        }


# å…¨å±€åˆ†ç‰‡ä¸Šä¼ ç®¡ç†å™¨å®ä¾‹
chunked_upload_manager = ChunkedUploadManager()